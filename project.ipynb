{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/bulatral42/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import time\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.fasttext import FastText\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk_inter_dist(texts, k=25):\n",
    "    X = np.zeros(shape=(len(texts), len(texts)), dtype=float)\n",
    "    for i in range(len(texts)):\n",
    "        words_i = set(texts[i].lower().strip().split())\n",
    "        for j in range(i + 1, len(texts)):\n",
    "            words_j = set(texts[j].lower().strip().split())\n",
    "            X[i, j] = X[j, i] = len(words_i & words_j) / (1 + len(words_i | words_j))\n",
    "    return np.sort(X, axis=1)[:, :-k-1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk_tfidf_cosine_dist(texts, ngrams=(1, 1), k=25):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=ngrams)\n",
    "    X = vectorizer.fit_transform(texts).toarray()\n",
    "    return np.sort(pairwise_distances(X, X, metric='cosine'), axis=1)[:, 1:k+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk_d2v_sim(texts, k=25):\n",
    "    tagged_data = [TaggedDocument(words=word_tokenize(doc), tags=[i]) \n",
    "                   for i, doc in enumerate(texts)]\n",
    "    \n",
    "    model_d2v = Doc2Vec(vector_size=50, alpha=0.025, min_count=2)\n",
    "    model_d2v.build_vocab(tagged_data)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        model_d2v.train(tagged_data,\n",
    "                        total_examples=model_d2v.corpus_count,\n",
    "                        epochs=model_d2v.epochs)\n",
    "\n",
    "    X = np.zeros((len(texts), 50))\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        X[i] = model_d2v.docvecs[i]\n",
    "    \n",
    "    return np.sort(pairwise_distances(X, X, metric='cosine'), axis=1)[:, 1:k+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pair_id, group_id, doc_id, target\n",
    "def get_features(data, k=25):\n",
    "    X = np.ndarray(shape=(0, 6 * k))\n",
    "    y = []\n",
    "    for gr_id in tqdm(data.group_id.unique()[:]):    \n",
    "        gr_len = data[data.group_id == gr_id].doc_id.values.size\n",
    "        \n",
    "        raw_texts = []\n",
    "        for doc_id in data[data.group_id == gr_id].doc_id.values:\n",
    "            with open('data_title_h16/' + str(doc_id) + '.dat.txt', mode='r') as doc:\n",
    "                raw_texts.append(doc.read())\n",
    "                    \n",
    "        with open('data/title_h16_' + str(gr_id) + '.txt', mode='r') as doc:\n",
    "            th = doc.read().split(';\\n')[:gr_len]\n",
    "        with open('data/paragraps_' + str(gr_id) + '.txt', mode='r') as doc:\n",
    "            par = doc.read().split(';\\n')[:gr_len]\n",
    "        # print(gr_id, len(th), len(par))\n",
    "        if 'target' in data.columns:\n",
    "            y += list(data[data.group_id == gr_id].target.values)\n",
    "        feat_gr = np.hstack((get_topk_inter_dist(raw_texts, k=k), \n",
    "                             get_topk_tfidf_cosine_dist(raw_texts, k=k), \n",
    "                             get_topk_d2v_sim(raw_texts, k=k),\n",
    "                             get_topk_inter_dist(par, k=k), \n",
    "                             get_topk_tfidf_cosine_dist(par, k=k), \n",
    "                             get_topk_d2v_sim(par, k=k)))\n",
    "        X = np.vstack((X, feat_gr))\n",
    "    if 'target' in data.columns:\n",
    "        return X, np.asarray(y)\n",
    "    else:\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28026\n"
     ]
    }
   ],
   "source": [
    "doc_to_title = {}\n",
    "with open('docs_titles.tsv') as f:\n",
    "    for num_line, line in enumerate(f):\n",
    "        if num_line == 0:\n",
    "            continue\n",
    "        data = line.strip().split('\\t', 1)\n",
    "        doc_id = int(data[0])\n",
    "        if len(data) == 1:\n",
    "            title = ''\n",
    "        else:\n",
    "            title = data[1]\n",
    "        doc_to_title[doc_id] = title\n",
    "print(len(doc_to_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('train_groups.csv')\n",
    "traingroups_titledata = {}\n",
    "for i in range(len(train_data)):\n",
    "    new_doc = train_data.iloc[i]\n",
    "    doc_group = new_doc['group_id']\n",
    "    doc_id = new_doc['doc_id']\n",
    "    target = new_doc['target']\n",
    "    title = doc_to_title[doc_id]\n",
    "    if doc_group not in traingroups_titledata:\n",
    "        traingroups_titledata[doc_group] = []\n",
    "    traingroups_titledata[doc_group].append((doc_id, title, target))\n",
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11691</td>\n",
       "      <td>130</td>\n",
       "      <td>6710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11692</td>\n",
       "      <td>130</td>\n",
       "      <td>4030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11693</td>\n",
       "      <td>130</td>\n",
       "      <td>5561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11694</td>\n",
       "      <td>130</td>\n",
       "      <td>4055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11695</td>\n",
       "      <td>130</td>\n",
       "      <td>4247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_id  group_id  doc_id\n",
       "0    11691       130    6710\n",
       "1    11692       130    4030\n",
       "2    11693       130    5561\n",
       "3    11694       130    4055\n",
       "4    11695       130    4247"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('test_groups.csv')\n",
    "testgroups_titledata = {}\n",
    "for i in range(len(test_data)):\n",
    "    new_doc = test_data.iloc[i]\n",
    "    doc_group = new_doc['group_id']\n",
    "    doc_id = new_doc['doc_id']\n",
    "    title = doc_to_title[doc_id]\n",
    "    if doc_group not in testgroups_titledata:\n",
    "        testgroups_titledata[doc_group] = []\n",
    "    testgroups_titledata[doc_group].append((doc_id, title))\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11691</td>\n",
       "      <td>130</td>\n",
       "      <td>6710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11692</td>\n",
       "      <td>130</td>\n",
       "      <td>4030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11693</td>\n",
       "      <td>130</td>\n",
       "      <td>5561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11694</td>\n",
       "      <td>130</td>\n",
       "      <td>4055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11695</td>\n",
       "      <td>130</td>\n",
       "      <td>4247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16622</th>\n",
       "      <td>28313</td>\n",
       "      <td>309</td>\n",
       "      <td>16637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16623</th>\n",
       "      <td>28314</td>\n",
       "      <td>309</td>\n",
       "      <td>16759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16624</th>\n",
       "      <td>28315</td>\n",
       "      <td>309</td>\n",
       "      <td>15358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16625</th>\n",
       "      <td>28316</td>\n",
       "      <td>309</td>\n",
       "      <td>17287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16626</th>\n",
       "      <td>28317</td>\n",
       "      <td>309</td>\n",
       "      <td>16026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16627 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pair_id  group_id  doc_id\n",
       "0        11691       130    6710\n",
       "1        11692       130    4030\n",
       "2        11693       130    5561\n",
       "3        11694       130    4055\n",
       "4        11695       130    4247\n",
       "...        ...       ...     ...\n",
       "16622    28313       309   16637\n",
       "16623    28314       309   16759\n",
       "16624    28315       309   15358\n",
       "16625    28316       309   17287\n",
       "16626    28317       309   16026\n",
       "\n",
       "[16627 rows x 3 columns]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [24:57<00:00, 11.61s/it]\n",
      "100%|██████████| 180/180 [37:19<00:00, 12.44s/it]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_features(train_data, k=25)\n",
    "X_test = get_features(test_data, k=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11690, 125) (11690,) (16627, 125)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_train, y_val_train = X_train[:9000], y_train[:9000]\n",
    "X_val_test, y_val_test = X_train[9000:], y_train[9000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc', SVC(class_weight='balanced', gamma='auto'))])"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto', class_weight='balanced')) # lgb.LGBMClassifier() # \n",
    "clf.fit(X_val_train, y_val_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2690,)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_pred = clf.predict(X_val_test)\n",
    "y_val_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 150) (9000,) (2690, 150)\n"
     ]
    }
   ],
   "source": [
    "print(X_val_train.shape, y_val_train.shape, X_val_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.7843784378437844\n"
     ]
    }
   ],
   "source": [
    "print('Validation score: {}'.format(f1_score(y_val_test, y_val_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc', SVC(class_weight='balanced', gamma='auto'))])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto', class_weight='balanced'))# lgb.LGBMClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11691</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11692</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11693</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11694</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11695</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target\n",
       "pair_id        \n",
       "11691         1\n",
       "11692         0\n",
       "11693         0\n",
       "11694         1\n",
       "11695         0"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = { 'pair_id': np.asarray(test_data.pair_id), 'target': y_pred }\n",
    "df = pd.DataFrame(data=data)\n",
    "df = df.set_index(keys=['pair_id'])\n",
    "df.to_csv('submitBoostHeaders.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5792\n",
      "10835\n",
      "3361\n",
      "8329\n"
     ]
    }
   ],
   "source": [
    "print((y_pred == 1).astype(int).sum())\n",
    "print((y_pred == 0).astype(int).sum())\n",
    "\n",
    "print((y_train == 1).astype(int).sum())\n",
    "print((y_train == 0).astype(int).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "скор на паблик лидерборде: 0.73223"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
